{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple generator and discriminator for CIFAR-10\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # TODO: Define the generator architecture for CIFAR-10\n",
    "        # consider that the output must match the size of the images (3*32*32)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 3*32*32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x).view(x.size(0), 3, 32,32)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # TODO: Define the discriminator architecture for CIFAR-10\n",
    "        # consider that:\n",
    "        # the input must match one image (3*32*32)\n",
    "        # the output must match a number\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     nn.Linear(3*32*32, 128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(128, 1),\n",
    "        #     nn.Sigmoid()\n",
    "        # )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Linear(128*8*8, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), 3, 32,32))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)\n",
    "\n",
    "# Define loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "# Data loading and preprocessing (using CIFAR-10 dataset)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "# dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(dataset), len(dataloader))\n",
    "# for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "#     print(images.shape, labels.shape)\n",
    "#     break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_images(images, nrow=4):\n",
    "    \"\"\"\n",
    "    Displays generated images in a grid.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Tensor of images to display.\n",
    "        nrow (int): Number of images per row in the grid.\n",
    "    \"\"\"\n",
    "    # Denormalize the images\n",
    "    images = images * 0.5 + 0.5  # Assuming images were normalized to [-1, 1]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    grid_img = vutils.make_grid(images.cpu(), nrow=nrow)\n",
    "    npimg = grid_img.numpy()\n",
    "\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Training loop\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            real_images, _ = data\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.view(batch_size, -1)\n",
    "            real_labels = torch.ones(batch_size, 1, 1, 1)\n",
    "            fake_labels = torch.zeros(batch_size, 1, 1, 1)\n",
    "\n",
    "\n",
    "            # Train the discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            outputs = discriminator(real_images)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            d_loss_real.backward()\n",
    "\n",
    "            z = torch.randn(batch_size, 100).to(real_images.device)\n",
    "            fake_images = generator(z)\n",
    "            outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train the generator\n",
    "            optimizer_G.zero_grad()\n",
    "            outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "\n",
    "        # Generate and save a sample of fake images\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(32, 100)\n",
    "                fake_samples = generator(z)\n",
    "                vutils.save_image(fake_samples, f'fake_cifar_samples_epoch_{epoch+1}.png', normalize=True)\n",
    "                show_generated_images(fake_samples)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Plot the loss curves\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(\"Generator and Discriminator Loss\")\n",
    "        plt.plot(g_losses, label=\"G Loss\")\n",
    "        plt.plot(d_losses, label=\"D Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f'loss_plot_epoch_{epoch+1}.png')\n",
    "        plt.show()\n",
    "\n",
    "# Main training loop\n",
    "train_gan(generator, discriminator, dataloader, num_epochs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML-CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
