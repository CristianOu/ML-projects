{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple generator and discriminator for CIFAR-10\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # TODO: Define the generator architecture for CIFAR-10\n",
    "        # consider that the output must match the size of the images (3*32*32)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(100, 1024),          # Larger layer size\n",
    "            nn.BatchNorm1d(1024),          # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(1024, 2048),         # Larger hidden layer\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(2048, 4096),         # Larger hidden layer\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(4096, 3*32*32),      # Match output to image size\n",
    "            nn.Tanh()                      # Tanh for normalized output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x).view(x.size(0), 3, 32,32)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # TODO: Define the discriminator architecture for CIFAR-10\n",
    "        # consider that:\n",
    "        # the input must match one image (3*32*32)\n",
    "        # the output must match a number\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 4096),     # Larger input layer\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),              # Add dropout to prevent overfitting\n",
    "            \n",
    "            nn.Linear(4096, 2048),        # Decrease layer size\n",
    "            nn.BatchNorm1d(2048),         # Batch normalization\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(2048, 1024),        # Smaller hidden layer\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(1024, 1),           # Output a single value (real/fake score)\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "    (7): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=4096, out_features=3072, bias=True)\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=4096, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Dropout(p=0.3, inplace=False)\n",
      "    (7): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (10): Dropout(p=0.3, inplace=False)\n",
      "    (11): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Files already downloaded and verified\n",
      "50000 782\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)\n",
    "\n",
    "# Define loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "# Data loading and preprocessing (using CIFAR-10 dataset)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "# dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(dataset), len(dataloader))\n",
    "# for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "#     print(images.shape, labels.shape)\n",
    "#     break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Main training loop\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 54\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, dataloader, num_epochs)\u001b[0m\n\u001b[0;32m     51\u001b[0m g_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     52\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 54\u001b[0m d_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43md_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     55\u001b[0m g_losses\u001b[38;5;241m.\u001b[39mappend(g_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def show_generated_images(images, nrow=8):\n",
    "    \"\"\"\n",
    "    Displays generated images in a grid.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Tensor of images to display.\n",
    "        nrow (int): Number of images per row in the grid.\n",
    "    \"\"\"\n",
    "    # Denormalize the images\n",
    "    images = images * 0.5 + 0.5  # Assuming images were normalized to [-1, 1]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    grid_img = vutils.make_grid(images.cpu(), nrow=nrow)\n",
    "    npimg = grid_img.numpy()\n",
    "\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Training loop\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            real_images, _ = data\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.view(batch_size, -1).to(device)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "\n",
    "            # Train the discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            outputs = discriminator(real_images)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            d_loss_real.backward()\n",
    "\n",
    "            z = torch.randn(batch_size, 100).to(device)\n",
    "            fake_images = generator(z)\n",
    "            outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train the generator\n",
    "            optimizer_G.zero_grad()\n",
    "            outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "\n",
    "        # Generate and save a sample of fake images\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(32, 100).to(device)\n",
    "                fake_samples = generator(z)\n",
    "                vutils.save_image(fake_samples, f'fake_cifar_samples_epoch_{epoch+1}.png', normalize=True)\n",
    "                show_generated_images(fake_samples)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Plot the loss curves\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(\"Generator and Discriminator Loss\")\n",
    "        plt.plot(g_losses, label=\"G Loss\")\n",
    "        plt.plot(d_losses, label=\"D Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f'loss_plot_epoch_{epoch+1}.png')\n",
    "        plt.show()\n",
    "\n",
    "# Main training loop\n",
    "train_gan(generator, discriminator, dataloader, num_epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML-CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
