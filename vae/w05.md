# Exercise week 5

This is your 5th mandatory exercise for the track "Advanced Machine Learning in Computer Vision".
The tasks will be published on 26th September, and must be completed until a week later, i.e. Thursday 03.10.2024, 08:15.
By that time you must fill out the checklist on the learnit page to indicate which tasks you volunteer to present.
You are very welcome to present incomplete solutions and describe what challenges you faced.

Reminder: Check the reading material for answers to questions which have not been addressed during the lecture.

## Task 1: Theory - Comparison of AE and VAE

The following tasks are providing questions as a reflection on key differences between AE and VAE.

a. Explain what the following are:

- undercomplete AE
- overcomplete AE
- denoising AE
- contractive AE
- bottleneck AE
- sparse AE

### Task 1a Answer:

**Undercomplete Autoencoder**: The latent space (hidden layer) is smaller than the input dimension, forcing the autoencoder to learn a compressed representation of the input. This encourages learning useful features by minimizing reconstruction error.

**Overcomplete Autoencoder**: The latent space is larger than the input dimension, allowing for more complex representations. However, without regularization, this may lead to learning the identity function, failing to extract meaningful features.

**Denoising Autoencoder (DAE)**: Trained to reconstruct the original input from a noisy version. It learns to capture the underlying structure of the data, making it robust to small perturbations or noise.

**Contractive Autoencoder (CAE)**: A regularization term is added to the loss function to minimize the sensitivity of the latent representation to small changes in the input. This forces the model to learn features that are robust to variations in input.

**Bottleneck Autoencoder**: Refers to an autoencoder with a narrow latent space (small bottleneck), forcing the model to learn compressed and efficient representations. Similar to undercomplete AE, it encourages dimensionality reduction.

**Sparse Autoencoder**: A sparsity constraint is added to the latent space, making most neurons inactive (zero values). This encourages the model to learn a sparse and efficient representation of the input, often useful for feature extraction.

b. Both AEs and VAEs are designed to reconstruct their inputs. How do their loss functions differ? Explain the key components of the VAE loss function (i.e., the reconstruction loss and KL divergence) and how they guide the training process.

[https://lilianweng.github.io/posts/2018-08-12-vae/](https://lilianweng.github.io/posts/2018-08-12-vae/)

### Task 1b Answer:

Autoencoders (AEs) and Variational Autoencoders (VAEs) are both designed to reconstruct their inputs, but their loss functions differ because VAEs incorporate probabilistic elements that AEs do not.

**Autoencoders (AEs)**:

AEs typically use a reconstruction loss function to minimize the difference between the input x and its reconstructed version $\hat{x}$.This is commonly done using Mean Squared Error (MSE) depending on the nature of the input data:
$Loss(AE)$ = MSE(x, $\hat{x}$)
This loss function focuses solely on how well the decoder can recreate the input from the encoded representation.

**Variational Autoencoders (VAEs)**:

The loss function for a VAE can be expressed as follows:

```math
\mathcal{L}(\theta, \phi; x, z, \beta) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - \beta D_{KL}(q_{\phi}(z|x) \| p(z))
```

where:

- $\mathcal{L}(\theta, \phi; x, z, \beta)$: the overall loss function that depends on the
  parameters of the decoder $\theta$, the encoder $\phi$, input data x, latent variable z, and a hyperparameter $\beta$
- $\mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)]$: This term represents the expected log likelihood of the data given the latent variables. It quantifies how well the model can reconstruct the input data $x$ from the latent representation $z$ produced by the encoder.
- $-\beta D_{KL}(q_{\phi}(z|x) \| p(z))$: This term is the negative scaled Kullback-Leibler divergence between the variational distribution $q_{\phi}(z|x)$ (the output of the encoder) and the prior distribution $p(z)$. This divergence acts as a regularizer, ensuring that the learned latent distribution does not deviate too much from the prior. By minimizing this term, the model is encouraged to learn a structured and meaningful latent space.

### Summary:

In contrast to standard Autoencoders that primarily focus on minimizing the reconstruction error, Variational Autoencoders introduce a regularization term through KL divergence, leading to a more robust representation of the latent space. This combination allows VAEs not only to reconstruct inputs effectively but also to generate new data samples by sampling from the learned latent distribution.

c. How does the latent space in an AE differ from that in a VAE? Why is the latent space of a VAE probabilistic?

### Task 1c Answer:

The latent spaces of Autoencoders (AEs) and Variational Autoencoders (VAEs) differ fundamentally in their structure and interpretation:
**Latent Space in Autoencoders (AEs)**

1. Deterministic Representation:
   - In standard Autoencoders, the latent space is deterministic. Given an input $x$, the encoder maps it to a single point in the latent space $z$. This means that each input corresponds to a unique latent representation.
2. Geometry:
   - The latent space geometry is shaped by the training data but does not have any probabilistic interpretation. The relationships and distances in this space depend solely on how the encoder has learned to compress the data.

**Latent Space in Variational Autoencoders (VAEs)**

1. Probabilistic Representation:
   - In contrast, VAEs utilize a probabilistic approach to the latent space. For a given input $x$, the encoder outputs parameters (mean and variance) of a probability distribution (typically a Gaussian) rather than a single point. Thus, each input maps to a distribution in the latent space, represented as $q_{\phi}(z|x)$
2. Sampling:
   - During the decoding phase, samples $z$ are drawn from this distribution. This introduces variability in the latent space, allowing multiple different latent representations for the same input, effectively capturing uncertainty and variation.
3. Structured Latent Space:
   - The probabilistic nature of the latent space encourages the model to learn a more structured representation. The Kullback-Leibler (KL) divergence term in the loss function regularizes the distribution of latent variables to be close to a prior distribution (usually a standard normal distribution). This ensures that the latent space is organized, enabling meaningful interpolations and sampling.

d. Explain a situation in which you would prefer to use a VAE over an AE, and vice versa, particularly in the context of Computer Vision.

### Task 1d Answer:

#### When to Prefer a VAE

Suppose you're working on generating new images similar to a given dataset, such as faces or handwritten digits.
VAEs excel in generative tasks because they map the input to a probabilistic latent space. By sampling from this latent space, the VAE can generate new, realistic images that resemble the original training data. Since the latent space is regularized (using KL divergence), it ensures that the samples drawn from it are meaningful, leading to smoother and more coherent generations.
**Example**: VAEs are commonly used for tasks like generating synthetic faces, producing interpolations between different images, or creating novel data for augmentation purposes in image datasets.

#### When to Prefer a VAE

Suppose your primary goal is to reduce the dimensionality of high-resolution images for feature extraction, without needing to generate new images.
AEs are excellent for deterministic image compression or dimensionality reduction. Their latent space is more compact and direct, making them ideal for tasks where the primary focus is to encode an image into a smaller feature space and then reconstruct it.
**Example**: AEs are suitable for image denoising tasks or reconstructing compressed images where the aim is to restore the original data as accurately as possible, without adding variability or probabilistic sampling.

## Task 2: Theory - Kullback-Leibler Divergence

The Kullback-Leibler (KL) Divergence gives a measure to quantify the difference between distributions. It is defined for the continuous and discrete case.
KL Divergence between two discrete random variables is defined as

$$
KL(q||p) = \sum_{x} q(x) \ln\left[\frac{q(x)}{p(x)} \right].
$$

Your task is to compute the KL Divergence between two Bernoulli distributions, where each is given as

$$
f(x|p) =  \begin{cases} p^x (1-p)^{1-x} &, \text{ if }x=0,1\\\ ~0 &, \text{ else,}  \end{cases}
$$

with parameters specified below.

a. Compute $KL(f(x|p_1)||f(x|p_2))$, and $KL(f(x|p_2)||f(x|p_1))$ for $p_1=0.4$, $p_2=0.8$ without toolboxes. You can do this by hand on paper or via coding. Keep in mind to only sum over the set of possible realisations $x\in\{0,1 \}$.

 b. Compute $KL(f(x|p_1)||f(x|p_2))$, and $KL(f(x|p_2)||f(x|p_1))$ for $p_1=0.4$ by varying $p_2$. Plot your results, with $p_2$ on the $x$-axis and $KL(\cdot ||\cdot )$ on the $y$-axis. (Do not use a toolbox or package for this, i.e. implement the discrete KL Divergence by yourself.)

Note:

- Edge cases have to be considered, e.g. p(x)=0
- You should not use a toolbox or package for this task. However, solutions on paper or you own code are both valid.

## Task 3: Theory - Transposed Convolution

In the following programming task you will encounter "transposed convolutions".
Your task is to fill this knowledge gap, by (re-)reading [PML] 14.4.2 Transposed convolution.
(In the reading material, you will find a direct link to [this article on medium](https://towardsdatascience.com/what-is-transposed-convolutional-layer-40e5e6e31c11).)

Your task is to define what a transposed convolution is, and explain how it is different or related to image convolutions you already know.

Note: If you found other helpful sources, share them with your peers and teachers. :)

### Task 3 Answer:

What is a Transposed Convolution?
A transposed convolution, also known as a deconvolution or upconvolution, is a type of convolution operation used in deep learning to increase the spatial resolution of an input feature map. It’s commonly used in architectures that involve upsampling or generating high-resolution output, such as in generative models like Variational Autoencoders (VAEs) or image segmentation networks like U-Net.

Despite the term "deconvolution," this operation is not the true mathematical inverse of a convolution. Instead, it’s a technique that allows for the reverse process of a standard convolution, where you expand a smaller input feature map into a larger output, making it suitable for tasks like generating or reconstructing images from compressed latent representations.

How Does Transposed Convolution Work?
In a standard convolution, you apply a filter over an input to produce an output of smaller spatial dimensions (depending on padding, stride, etc.). For example, applying a 3x3 filter with stride 2 on a 7x7 image will result in a smaller 3x3 output.

## Task 4: Programming - AE

Follow [this tutorial](https://www.tensorflow.org/tutorials/generative/autoencoder).
the basics, image denoising, and anomaly detection.
Notice the buttons at the top referring to colab, github, and notebook download. (We provide the exact notebook in the file "autoencoder.ipynb")
The complete tutorial will guide you through the implementation of an autoencoder for

1. reconstruction
2. denoising, and
3. anomaly detection

For this task focus on the first two applications reconstruction and denoising.
Choose reconstruction or denoising as your preferred starting point.

a. For the selected example: Run the code to reconstruct the images from Fashion MNIST. Investigate the code and answer the following questions:

- What is the architecture of the AE? (You can draw a diagram if you find it helpful.)
- How many parameters does the model have?
- Which activation functions are used?
- What is the loss function?
- What is the optimizer?
  Elaborate on other design choices you noticed.

## Task 4a Answer:

#### Architecture of the Autoencoder (AE)

i) The Autoencoder (AE) has the following architecture:

**Encoder**:

- Input: 28x28 grayscale images from the Fashion MNIST dataset (each image is flattened into a vector of size 784).
- Dense Layer: A fully connected layer with latent_dim = 64 units and ReLU activation.

**Decoder**:

- Dense Layer: A fully connected layer with the same number of units as the input size (28x28 = 784), with a Sigmoid activation function.
- Reshape Layer: Reshapes the output back into a 28x28 image.

ii) Parameters of the Model
To calculate the total number of parameters, we consider the encoder and decoder separately:

Encoder:

The first Dense layer maps the flattened input (size 784) to the latent dimension (size 64).
Parameters = $784×64+64=50240$ (weights + biases)
Decoder:

The Dense layer maps from the latent dimension (size 64) back to the flattened input (size 784).
Parameters = $64×784+784=51040$ (weights + biases)

Total parameters: $50240+51040=101280$

iii) Activation Functions
**Encoder**: The encoder uses the ReLU activation function in the Dense layer.
**Decoder**: The decoder uses the Sigmoid activation function to map the output back into a range between 0 and 1, appropriate for image pixel values.

iv) The Autoencoder is compiled with the Mean Squared Error (MSE) loss function. This measures the difference between the input image and its reconstruction (output).

v) The optimizer used is Adam (Adaptive Moment Estimation). Adam is an adaptive learning rate optimization algorithm that combines the benefits of AdaGrad and RMSProp. It is well-suited for training deep neural networks and is widely used in practice.

Other design choices:
- Different Latent Dimension: The latent dimension is set to 64, which is a common choice for this type of architecture. A higher latent dimension can capture more complex features but may lead to overfitting.
- Number of Epochs: The model is trained for 10 epochs, which is a reasonable number for convergence on the Fashion MNIST dataset. More epochs could lead to better performance but may also increase the risk of overfitting.
- activation functions: The ReLU activation function is used in the encoder, which is a common choice for hidden layers in neural networks. The Sigmoid activation function is used in the decoder to map the output to the range [0, 1], suitable for image pixel values. These choices are standard for autoencoder architectures.

b. Add a plot to depict the training and validation loss during training. Did the training converge? How would you identify over- or underfitting?

c. Save the results, and refer to the baseline model as model A. The goal of this exercise is to make changes, then investigate the differences.

<ul>
 <li> Model B: </li>
 <ul>
 <li> if reconstruction: Change the "Dense" to "Conv2D" in model A.  (Note some more modifications might be needed.) </li>
 <li> if denoising: Change the "Conv2DTranspose" to "Conv2D" in model A. (Note some more modifications might be needed.) </li>
  </ul>
<li> Model C: Add another layer of your choice in the encoder of model A. </li>
 </ul>

For all models save the loss curves, and elaborate on the differences.

- How well do the models reconstruct the images?
- Does one perform significantly worse or better than the others?

d. Establish a model D: Adapt model A in a way of your choice. Note: it must be a different adaptation than the model B, and model C.
Describe your motivation for the change.
Compare the model D to the others as before.

## NON-mandatory task

The last task focussed on you chosen use-case reconstruction or denoising.
However, the tutorial contains 2 more use-cases, e.g. anomaly detection.
Your additional (optional) task is to adapt the two other models in an attempt to receive better results.
